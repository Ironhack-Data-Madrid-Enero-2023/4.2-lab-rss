{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with RSS Feeds\n",
    "\n",
    "\n",
    "Lesson Goals\n",
    "\n",
    "    Learn about the feedparser library\n",
    "    Use feedparser to parse RSS feeds\n",
    "    Explore the components of parsed RSS feeds\n",
    "    Convert results into data frames and conduct analysis\n",
    "\n",
    "Introduction\n",
    "\n",
    "In the previous lesson, we learned how to use Python to extract structured information from web APIs. In this lesson, we are going to take a look at another source of structured web content called RSS. RSS stands for Rich Site Summary or Really Simple Syndication, and it is a type of web feed which allows users and applications to access updates to online content in a standardized, computer-readable format (typically XML).\n",
    "\n",
    "Python has an excellent library called feedparser that is very useful for reading and parsing RSS feeds. We are going to be using this library throughout the lesson, so let's make sure it is installed and imported.\n",
    "\n",
    "$ pip install feedparser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSS Feed Versions Formats\n",
    "\n",
    "Due to the way web feeds evolved, there are various versions of RSS (0.9X, 1.0, 2.0, etc.) as well as alternate forms of feeds (Atom, CDF, etc.). We would have to worry about slight differences in formats if we were going to parse the feeds manually, but feedparser is able to handle all of them, so that is one less thing we need to worry about.\n",
    "\n",
    "\n",
    "# Parsing RSS Feeds\n",
    "\n",
    "To parse an RSS feed with feedparser, you just need to call its parse method and pass it a URL. Let's take a look at an example using the RSS feed for the tech subreddit category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = feedparser.parse('https://www.reddit.com/r/tech.rss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a look at the results, we will see a nested dictionary structure that contains a lot of information and looks something like the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tags': [{'term': 'tech', 'scheme': None, 'label': 'r/tech'}], 'updated': '2023-02-07T14:09:04+00:00', 'updated_parsed': time.struct_time(tm_year=2023, tm_mon=2, tm_mday=7, tm_hour=14, tm_min=9, tm_sec=4, tm_wday=1, tm_yday=38, tm_isdst=0), 'icon': 'https://www.redditstatic.com/icon.png/', 'id': 'https://www.reddit.com/r/tech.rss', 'guidislink': True, 'link': 'https://www.reddit.com/r/tech', 'links': [{'rel': 'self', 'href': 'https://www.reddit.com/r/tech.rss', 'type': 'application/atom+xml'}, {'rel': 'alternate', 'href': 'https://www.reddit.com/r/tech', 'type': 'text/html'}], 'logo': 'https://f.thumbs.redditmedia.com/kI7eGVG6kaObGTdM.png', 'subtitle': 'The goal of /r/tech is to provide a space dedicated to the intelligent discussion of innovations and changes to technology in our ever changing world. We focus on high quality news articles about technology and informative and thought provoking self posts.', 'subtitle_detail': {'type': 'text/plain', 'language': None, 'base': 'https://www.reddit.com/r/tech.rss', 'value': 'The goal of /r/tech is to provide a space dedicated to the intelligent discussion of innovations and changes to technology in our ever changing world. We focus on high quality news articles about technology and informative and thought provoking self posts.'}, 'title': '/r/tech: Technological innovations and changes.', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'https://www.reddit.com/r/tech.rss', 'value': '/r/tech: Technological innovations and changes.'}}\n"
     ]
    }
   ],
   "source": [
    "print(reddit['feed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great because we can now use what we learned earlier in the program about working with data structures to explore and extract the information we need from this.\n",
    "\n",
    "\n",
    "\n",
    "# Exploring the Parsed Feed\n",
    "\n",
    "Let's take a look at the first level of dictionary keys from the results and see what each of them looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bozo', 'entries', 'feed', 'headers', 'href', 'status', 'encoding', 'version', 'namespaces'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the different components of the RSS feed, and each of them is going to contain information about something more specific. For example, feed is going to contain information about this Reddit RSS feed, entries is going to contain information about the specific entries in the feed, etc.\n",
    "\n",
    "Since the feed component is now structured as just a dictionary inside the larger dictionary, we can view its keys to get a sense of what type of information is available to us within the feed dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tags', 'updated', 'updated_parsed', 'icon', 'id', 'guidislink', 'link', 'links', 'logo', 'subtitle', 'subtitle_detail', 'title', 'title_detail'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.feed.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that we would be able to extract any tags for the feed, when the feed was updated, and the icon image for the feed as well as the feed title, subtitle, and various other pieces of information about it. You can see what each of those looks like by calling each component from reddit.feed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'term': 'tech', 'scheme': None, 'label': 'r/tech'}]\n",
      "\n",
      "https://www.redditstatic.com/icon.png/\n",
      "\n",
      "/r/tech: Technological innovations and changes.\n",
      "\n",
      "The goal of /r/tech is to provide a space dedicated to the intelligent discussion of innovations and changes to technology in our ever changing world. We focus on high quality news articles about technology and informative and thought provoking self posts.\n"
     ]
    }
   ],
   "source": [
    "print (reddit.feed.tags)\n",
    "print ('')\n",
    "print (reddit.feed.icon)\n",
    "print ('')\n",
    "print (reddit.feed.title)\n",
    "print ('')\n",
    "print (reddit.feed.subtitle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great, but the most interesting part of the feed is probably going to be the entries. We can access them as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'authors': [{'name': '/u/upyoars',\n",
       "   'href': 'https://www.reddit.com/user/upyoars'}],\n",
       " 'author_detail': {'name': '/u/upyoars',\n",
       "  'href': 'https://www.reddit.com/user/upyoars'},\n",
       " 'href': 'https://www.reddit.com/user/upyoars',\n",
       " 'author': '/u/upyoars',\n",
       " 'tags': [{'term': 'tech', 'scheme': None, 'label': 'r/tech'}],\n",
       " 'content': [{'type': 'text/html',\n",
       "   'language': None,\n",
       "   'base': 'https://www.reddit.com/r/tech.rss',\n",
       "   'value': '&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/upyoars\"> /u/upyoars </a> <br /> <span><a href=\"https://money.com/used-tesla-prices-gas-powered-cars/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/tech/comments/10vnuny/used_tesla_prices_drop_more_than_costs_for/\">[comments]</a></span>'}],\n",
       " 'summary': '&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/upyoars\"> /u/upyoars </a> <br /> <span><a href=\"https://money.com/used-tesla-prices-gas-powered-cars/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/tech/comments/10vnuny/used_tesla_prices_drop_more_than_costs_for/\">[comments]</a></span>',\n",
       " 'id': 'https://www.reddit.com/r/t3_10vnuny',\n",
       " 'guidislink': True,\n",
       " 'link': 'https://www.reddit.com/r/tech/comments/10vnuny/used_tesla_prices_drop_more_than_costs_for/',\n",
       " 'links': [{'href': 'https://www.reddit.com/r/tech/comments/10vnuny/used_tesla_prices_drop_more_than_costs_for/',\n",
       "   'rel': 'alternate',\n",
       "   'type': 'text/html'}],\n",
       " 'updated': '2023-02-07T00:59:37+00:00',\n",
       " 'updated_parsed': time.struct_time(tm_year=2023, tm_mon=2, tm_mday=7, tm_hour=0, tm_min=59, tm_sec=37, tm_wday=1, tm_yday=38, tm_isdst=0),\n",
       " 'published': '2023-02-07T00:59:37+00:00',\n",
       " 'published_parsed': time.struct_time(tm_year=2023, tm_mon=2, tm_mday=7, tm_hour=0, tm_min=59, tm_sec=37, tm_wday=1, tm_yday=38, tm_isdst=0),\n",
       " 'title': 'Used Tesla Prices Drop More Than Costs for Gas-Powered Cars',\n",
       " 'title_detail': {'type': 'text/plain',\n",
       "  'language': None,\n",
       "  'base': 'https://www.reddit.com/r/tech.rss',\n",
       "  'value': 'Used Tesla Prices Drop More Than Costs for Gas-Powered Cars'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.entries[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data structure within this seems to be a list where each entry is an element that contains a dictionary with the information for each entry. We can access the individual entries via indexing and then we can look at the keys available for the entry by calling the keys() method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['authors', 'author_detail', 'href', 'author', 'tags', 'content', 'summary', 'id', 'guidislink', 'link', 'links', 'updated', 'updated_parsed', 'published', 'published_parsed', 'title', 'title_detail'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.entries[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to obtain a particular piece of data for an entry, we could just index that entry and then call the key for the information we wanted. For example, if we wanted to get the title of the third entry, we would obtain it as follows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Samsung’s first OLED gaming monitor costs $1,499.99.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.entries[2].title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the titles for all the entries, we could use a list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Used Tesla Prices Drop More Than Costs for Gas-Powered Cars', 'An AI Wrote My Will. I’m an Estate Lawyer. Goodbye Career.', 'Samsung’s first OLED gaming monitor costs $1,499.99.', 'Explained | What are voice deepfakes and how are they used?', 'Google trials its own AI chatbot Bard after success of ChatGPT | Google', 'This Antarctic EV goes where other electric vehicles can’t tread', 'Microsoft reportedly plans to update Bing with a faster version of ChatGPT as early as next week', 'ChatGPT Passes Google Coding Interview for Level 3 Engineer With $183K Salary', '“We have split natural seawater into oxygen and hydrogen with nearly 100 per cent efficiency, to produce green hydrogen by electrolysis, using a non-precious and cheap catalyst in a commercial electrolyser,” said Professor Qiao.', 'An easy-to-repair modular laptop is launching this summer', 'Paper-thin solar cell can turn any surface into a power source Researchers develop a scalable fabrication technique to produce ultrathin, lightweight solar cells that can be seamlessly added to any surface.', 'Engineers invent vertical, full-color microscopic LEDs', 'AI-Generated Voice Firm Clamps Down After 4chan Makes Celebrity Voices for Abuse', 'ChatGPT sets record for fastest-growing user base', \"New tech's potential to significantly reduce energy storage costs\", 'Hydrogel Brings Cooling Relief to Electronics. The gel absorbs moisture from air to cool electronics passively.', \"Dyson's Air Purifying Headphones promises to eliminate both unwanted noise and unwanted air particles.\", '10 Breakthrough Technologies 2023 - MIT Technology Review', 'OpenAI releases tool to detect AI-generated text, including from ChatGPT', 'toroidal propellers turn your drones + boats into noiseless machines', 'Canadian team discovers power-draining flaw in most laptop and phone batteries', 'How a CIA-funded startup plans to bring back the dodo bird', 'AI-Powered Brain Implant Smashes Speed Record for Turning Thoughts Into Text', 'New method to control electron spin paves the way for efficient quantum computers', 'Researchers created a sticky drone to collect environmental DNA from forest canopies']\n"
     ]
    }
   ],
   "source": [
    "titles = [reddit.entries[i].title for i in range(len(reddit.entries))]\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Data From an RSS Feed\n",
    "\n",
    "Thus far, feedparser has helped us obtain data from an RSS feed and structure in a way that makes it easy for us to explore it and extract the information we need. If we wanted to analyze the data further, we could leverage the Pandas library and create a data frame containing the information about entries in the feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>author_detail</th>\n",
       "      <th>href</th>\n",
       "      <th>author</th>\n",
       "      <th>tags</th>\n",
       "      <th>content</th>\n",
       "      <th>summary</th>\n",
       "      <th>id</th>\n",
       "      <th>guidislink</th>\n",
       "      <th>link</th>\n",
       "      <th>links</th>\n",
       "      <th>updated</th>\n",
       "      <th>updated_parsed</th>\n",
       "      <th>published</th>\n",
       "      <th>published_parsed</th>\n",
       "      <th>title</th>\n",
       "      <th>title_detail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'name': '/u/upyoars', 'href': 'https://www.r...</td>\n",
       "      <td>{'name': '/u/upyoars', 'href': 'https://www.re...</td>\n",
       "      <td>https://www.reddit.com/user/upyoars</td>\n",
       "      <td>/u/upyoars</td>\n",
       "      <td>[{'term': 'tech', 'scheme': None, 'label': 'r/...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>&amp;#32; submitted by &amp;#32; &lt;a href=\"https://www....</td>\n",
       "      <td>https://www.reddit.com/r/t3_10vnuny</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.reddit.com/r/tech/comments/10vnuny...</td>\n",
       "      <td>[{'href': 'https://www.reddit.com/r/tech/comme...</td>\n",
       "      <td>2023-02-07T00:59:37+00:00</td>\n",
       "      <td>(2023, 2, 7, 0, 59, 37, 1, 38, 0)</td>\n",
       "      <td>2023-02-07T00:59:37+00:00</td>\n",
       "      <td>(2023, 2, 7, 0, 59, 37, 1, 38, 0)</td>\n",
       "      <td>Used Tesla Prices Drop More Than Costs for Gas...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'name': '/u/NZLaw', 'href': 'https://www.red...</td>\n",
       "      <td>{'name': '/u/NZLaw', 'href': 'https://www.redd...</td>\n",
       "      <td>https://www.reddit.com/user/NZLaw</td>\n",
       "      <td>/u/NZLaw</td>\n",
       "      <td>[{'term': 'tech', 'scheme': None, 'label': 'r/...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>&amp;#32; submitted by &amp;#32; &lt;a href=\"https://www....</td>\n",
       "      <td>https://www.reddit.com/r/t3_10vzzaw</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.reddit.com/r/tech/comments/10vzzaw...</td>\n",
       "      <td>[{'href': 'https://www.reddit.com/r/tech/comme...</td>\n",
       "      <td>2023-02-07T11:53:11+00:00</td>\n",
       "      <td>(2023, 2, 7, 11, 53, 11, 1, 38, 0)</td>\n",
       "      <td>2023-02-07T11:53:11+00:00</td>\n",
       "      <td>(2023, 2, 7, 11, 53, 11, 1, 38, 0)</td>\n",
       "      <td>An AI Wrote My Will. I’m an Estate Lawyer. Goo...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'name': '/u/SUPRVLLAN', 'href': 'https://www...</td>\n",
       "      <td>{'name': '/u/SUPRVLLAN', 'href': 'https://www....</td>\n",
       "      <td>https://www.reddit.com/user/SUPRVLLAN</td>\n",
       "      <td>/u/SUPRVLLAN</td>\n",
       "      <td>[{'term': 'tech', 'scheme': None, 'label': 'r/...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>&amp;#32; submitted by &amp;#32; &lt;a href=\"https://www....</td>\n",
       "      <td>https://www.reddit.com/r/t3_10vcrfu</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.reddit.com/r/tech/comments/10vcrfu...</td>\n",
       "      <td>[{'href': 'https://www.reddit.com/r/tech/comme...</td>\n",
       "      <td>2023-02-06T17:40:54+00:00</td>\n",
       "      <td>(2023, 2, 6, 17, 40, 54, 0, 37, 0)</td>\n",
       "      <td>2023-02-06T17:40:54+00:00</td>\n",
       "      <td>(2023, 2, 6, 17, 40, 54, 0, 37, 0)</td>\n",
       "      <td>Samsung’s first OLED gaming monitor costs $1,4...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'name': '/u/PrismetricTech', 'href': 'https:...</td>\n",
       "      <td>{'name': '/u/PrismetricTech', 'href': 'https:/...</td>\n",
       "      <td>https://www.reddit.com/user/PrismetricTech</td>\n",
       "      <td>/u/PrismetricTech</td>\n",
       "      <td>[{'term': 'tech', 'scheme': None, 'label': 'r/...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>&amp;#32; submitted by &amp;#32; &lt;a href=\"https://www....</td>\n",
       "      <td>https://www.reddit.com/r/t3_10vvh4z</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.reddit.com/r/tech/comments/10vvh4z...</td>\n",
       "      <td>[{'href': 'https://www.reddit.com/r/tech/comme...</td>\n",
       "      <td>2023-02-07T07:05:48+00:00</td>\n",
       "      <td>(2023, 2, 7, 7, 5, 48, 1, 38, 0)</td>\n",
       "      <td>2023-02-07T07:05:48+00:00</td>\n",
       "      <td>(2023, 2, 7, 7, 5, 48, 1, 38, 0)</td>\n",
       "      <td>Explained | What are voice deepfakes and how a...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'name': '/u/Tao_Dragon', 'href': 'https://ww...</td>\n",
       "      <td>{'name': '/u/Tao_Dragon', 'href': 'https://www...</td>\n",
       "      <td>https://www.reddit.com/user/Tao_Dragon</td>\n",
       "      <td>/u/Tao_Dragon</td>\n",
       "      <td>[{'term': 'tech', 'scheme': None, 'label': 'r/...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>&amp;#32; submitted by &amp;#32; &lt;a href=\"https://www....</td>\n",
       "      <td>https://www.reddit.com/r/t3_10vysjh</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.reddit.com/r/tech/comments/10vysjh...</td>\n",
       "      <td>[{'href': 'https://www.reddit.com/r/tech/comme...</td>\n",
       "      <td>2023-02-07T10:40:29+00:00</td>\n",
       "      <td>(2023, 2, 7, 10, 40, 29, 1, 38, 0)</td>\n",
       "      <td>2023-02-07T10:40:29+00:00</td>\n",
       "      <td>(2023, 2, 7, 10, 40, 29, 1, 38, 0)</td>\n",
       "      <td>Google trials its own AI chatbot Bard after su...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             authors  \\\n",
       "0  [{'name': '/u/upyoars', 'href': 'https://www.r...   \n",
       "1  [{'name': '/u/NZLaw', 'href': 'https://www.red...   \n",
       "2  [{'name': '/u/SUPRVLLAN', 'href': 'https://www...   \n",
       "3  [{'name': '/u/PrismetricTech', 'href': 'https:...   \n",
       "4  [{'name': '/u/Tao_Dragon', 'href': 'https://ww...   \n",
       "\n",
       "                                       author_detail  \\\n",
       "0  {'name': '/u/upyoars', 'href': 'https://www.re...   \n",
       "1  {'name': '/u/NZLaw', 'href': 'https://www.redd...   \n",
       "2  {'name': '/u/SUPRVLLAN', 'href': 'https://www....   \n",
       "3  {'name': '/u/PrismetricTech', 'href': 'https:/...   \n",
       "4  {'name': '/u/Tao_Dragon', 'href': 'https://www...   \n",
       "\n",
       "                                         href             author  \\\n",
       "0         https://www.reddit.com/user/upyoars         /u/upyoars   \n",
       "1           https://www.reddit.com/user/NZLaw           /u/NZLaw   \n",
       "2       https://www.reddit.com/user/SUPRVLLAN       /u/SUPRVLLAN   \n",
       "3  https://www.reddit.com/user/PrismetricTech  /u/PrismetricTech   \n",
       "4      https://www.reddit.com/user/Tao_Dragon      /u/Tao_Dragon   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [{'term': 'tech', 'scheme': None, 'label': 'r/...   \n",
       "1  [{'term': 'tech', 'scheme': None, 'label': 'r/...   \n",
       "2  [{'term': 'tech', 'scheme': None, 'label': 'r/...   \n",
       "3  [{'term': 'tech', 'scheme': None, 'label': 'r/...   \n",
       "4  [{'term': 'tech', 'scheme': None, 'label': 'r/...   \n",
       "\n",
       "                                             content  \\\n",
       "0  [{'type': 'text/html', 'language': None, 'base...   \n",
       "1  [{'type': 'text/html', 'language': None, 'base...   \n",
       "2  [{'type': 'text/html', 'language': None, 'base...   \n",
       "3  [{'type': 'text/html', 'language': None, 'base...   \n",
       "4  [{'type': 'text/html', 'language': None, 'base...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  &#32; submitted by &#32; <a href=\"https://www....   \n",
       "1  &#32; submitted by &#32; <a href=\"https://www....   \n",
       "2  &#32; submitted by &#32; <a href=\"https://www....   \n",
       "3  &#32; submitted by &#32; <a href=\"https://www....   \n",
       "4  &#32; submitted by &#32; <a href=\"https://www....   \n",
       "\n",
       "                                    id  guidislink  \\\n",
       "0  https://www.reddit.com/r/t3_10vnuny        True   \n",
       "1  https://www.reddit.com/r/t3_10vzzaw        True   \n",
       "2  https://www.reddit.com/r/t3_10vcrfu        True   \n",
       "3  https://www.reddit.com/r/t3_10vvh4z        True   \n",
       "4  https://www.reddit.com/r/t3_10vysjh        True   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.reddit.com/r/tech/comments/10vnuny...   \n",
       "1  https://www.reddit.com/r/tech/comments/10vzzaw...   \n",
       "2  https://www.reddit.com/r/tech/comments/10vcrfu...   \n",
       "3  https://www.reddit.com/r/tech/comments/10vvh4z...   \n",
       "4  https://www.reddit.com/r/tech/comments/10vysjh...   \n",
       "\n",
       "                                               links  \\\n",
       "0  [{'href': 'https://www.reddit.com/r/tech/comme...   \n",
       "1  [{'href': 'https://www.reddit.com/r/tech/comme...   \n",
       "2  [{'href': 'https://www.reddit.com/r/tech/comme...   \n",
       "3  [{'href': 'https://www.reddit.com/r/tech/comme...   \n",
       "4  [{'href': 'https://www.reddit.com/r/tech/comme...   \n",
       "\n",
       "                     updated                      updated_parsed  \\\n",
       "0  2023-02-07T00:59:37+00:00   (2023, 2, 7, 0, 59, 37, 1, 38, 0)   \n",
       "1  2023-02-07T11:53:11+00:00  (2023, 2, 7, 11, 53, 11, 1, 38, 0)   \n",
       "2  2023-02-06T17:40:54+00:00  (2023, 2, 6, 17, 40, 54, 0, 37, 0)   \n",
       "3  2023-02-07T07:05:48+00:00    (2023, 2, 7, 7, 5, 48, 1, 38, 0)   \n",
       "4  2023-02-07T10:40:29+00:00  (2023, 2, 7, 10, 40, 29, 1, 38, 0)   \n",
       "\n",
       "                   published                    published_parsed  \\\n",
       "0  2023-02-07T00:59:37+00:00   (2023, 2, 7, 0, 59, 37, 1, 38, 0)   \n",
       "1  2023-02-07T11:53:11+00:00  (2023, 2, 7, 11, 53, 11, 1, 38, 0)   \n",
       "2  2023-02-06T17:40:54+00:00  (2023, 2, 6, 17, 40, 54, 0, 37, 0)   \n",
       "3  2023-02-07T07:05:48+00:00    (2023, 2, 7, 7, 5, 48, 1, 38, 0)   \n",
       "4  2023-02-07T10:40:29+00:00  (2023, 2, 7, 10, 40, 29, 1, 38, 0)   \n",
       "\n",
       "                                               title  \\\n",
       "0  Used Tesla Prices Drop More Than Costs for Gas...   \n",
       "1  An AI Wrote My Will. I’m an Estate Lawyer. Goo...   \n",
       "2  Samsung’s first OLED gaming monitor costs $1,4...   \n",
       "3  Explained | What are voice deepfakes and how a...   \n",
       "4  Google trials its own AI chatbot Bard after su...   \n",
       "\n",
       "                                        title_detail  \n",
       "0  {'type': 'text/plain', 'language': None, 'base...  \n",
       "1  {'type': 'text/plain', 'language': None, 'base...  \n",
       "2  {'type': 'text/plain', 'language': None, 'base...  \n",
       "3  {'type': 'text/plain', 'language': None, 'base...  \n",
       "4  {'type': 'text/plain', 'language': None, 'base...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(reddit.entries)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the information in a data frame, we can use Pandas to perform a variety of aggregations and calculations. For example, suppose we wanted to know which author has posted the most entries. We could do that by aggregating by author, counting the number of entry titles, and then sorting the results in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>entries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/u/Sariel007</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/u/MichaelTen</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/u/fagnerbrack</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/u/Tao_Dragon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/u/upyoars</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/u/raynot978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/u/postalex</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/u/cupramrob</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/u/ageaid904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/u/Best_Cauliflowers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/u/ChickenTeriyakiBoy1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/u/SarahMagical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/u/SUPRVLLAN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/u/Rocky_Mountain_Way</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/u/PrismetricTech</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/u/NZLaw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/u/JackFisherBooks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/u/whitecastle92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    author  entries\n",
       "9             /u/Sariel007        4\n",
       "3            /u/MichaelTen        4\n",
       "13          /u/fagnerbrack        2\n",
       "10           /u/Tao_Dragon        1\n",
       "16              /u/upyoars        1\n",
       "15            /u/raynot978        1\n",
       "14             /u/postalex        1\n",
       "12            /u/cupramrob        1\n",
       "11            /u/ageaid904        1\n",
       "0     /u/Best_Cauliflowers        1\n",
       "1   /u/ChickenTeriyakiBoy1        1\n",
       "8          /u/SarahMagical        1\n",
       "7             /u/SUPRVLLAN        1\n",
       "6    /u/Rocky_Mountain_Way        1\n",
       "5        /u/PrismetricTech        1\n",
       "4                 /u/NZLaw        1\n",
       "2       /u/JackFisherBooks        1\n",
       "17        /u/whitecastle92        1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors = df.groupby('author', as_index=False).agg({'title':'count'})\n",
    "authors.columns = ['author', 'entries']\n",
    "authors.sort_values('entries', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, if we wanted to see which entries had the longest titles, we could create a new column called title_length that contains the number of characters in the title and then sort the data frame by that new column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>title_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>“We have split natural seawater into oxygen an...</td>\n",
       "      <td>/u/Sariel007</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Paper-thin solar cell can turn any surface int...</td>\n",
       "      <td>/u/Sariel007</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hydrogel Brings Cooling Relief to Electronics....</td>\n",
       "      <td>/u/Sariel007</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Dyson's Air Purifying Headphones promises to e...</td>\n",
       "      <td>/u/fagnerbrack</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Microsoft reportedly plans to update Bing with...</td>\n",
       "      <td>/u/raynot978</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title          author  \\\n",
       "8   “We have split natural seawater into oxygen an...    /u/Sariel007   \n",
       "10  Paper-thin solar cell can turn any surface int...    /u/Sariel007   \n",
       "15  Hydrogel Brings Cooling Relief to Electronics....    /u/Sariel007   \n",
       "16  Dyson's Air Purifying Headphones promises to e...  /u/fagnerbrack   \n",
       "6   Microsoft reportedly plans to update Bing with...    /u/raynot978   \n",
       "\n",
       "    title_length  \n",
       "8            228  \n",
       "10           206  \n",
       "15           111  \n",
       "16           102  \n",
       "6             96  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title_length'] = df['title'].apply(len)\n",
    "df[['title', 'author', 'title_length']].sort_values('title_length', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are just a couple of the things you can analyze about the entries using the information we were able to obtain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
